{"ast":null,"code":"export default class Voice {\n  constructor() {\n    this.synth = window.speechSynthesis;\n    this.context = new (window.AudioContext || window.webkitAudioContext)();\n    this.streamDestination = this.context.createMediaStreamDestination();\n    this.source1 = this.context.createBufferSource();\n    this.source2 = this.context.createBufferSource();\n    this.source3 = this.context.createBufferSource();\n    this.source4 = this.context.createBufferSource();\n    this.bufferSource = this.context.createBufferSource();\n  }\n\n  say(script) {\n    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n      console.log('getUserMedia supported.');\n      navigator.mediaDevices.getUserMedia({\n        audio: true\n      }).then(stream => {\n        const mediaRecorder = new MediaRecorder(stream);\n        const utterance = new SpeechSynthesisUtterance(script);\n\n        utterance.onend = () => {\n          mediaRecorder.stop();\n\n          mediaRecorder.ondataavailable = e => {\n            e.data.arrayBuffer().then(buffer => {\n              console.log(buffer);\n              this.context.decodeAudioData(buffer, audioBuffer => {\n                console.log(audioBuffer);\n                const combinedBuffer = new AudioBuffer(22050, 22050);\n                const combinedChannelData = audioBuffer.getChannelData(0) + audioBuffer.getChannelData(0).slice(10000);\n                const channelMerger = this.context.createChannelMerger(4);\n                this.source1.buffer = combinedBuffer;\n                this.source2.buffer = combinedBuffer;\n                this.source3.buffer = combinedBuffer;\n                this.source4.buffer = combinedBuffer;\n                this.source1.connect(this.context.destination);\n                this.source2.connect(this.context.destination);\n                this.source3.connect(this.context.destination);\n                this.source4.connect(this.context.destination);\n                this.source1.start();\n                this.source2.start();\n                this.source3.start();\n                this.source4.start();\n              });\n            });\n          };\n        };\n\n        mediaRecorder.start();\n        this.synth.speak(utterance);\n      });\n    }\n  }\n\n  loop() {\n    if (!window) {\n      return;\n    }\n\n    return;\n  }\n\n  save() {\n    if (!window) {\n      return;\n    }\n\n    return;\n  }\n\n}","map":{"version":3,"sources":["/Users/henrysteinitz/Desktop/soulstream/lib/voice/voice.js"],"names":["Voice","constructor","synth","window","speechSynthesis","context","AudioContext","webkitAudioContext","streamDestination","createMediaStreamDestination","source1","createBufferSource","source2","source3","source4","bufferSource","say","script","navigator","mediaDevices","getUserMedia","console","log","audio","then","stream","mediaRecorder","MediaRecorder","utterance","SpeechSynthesisUtterance","onend","stop","ondataavailable","e","data","arrayBuffer","buffer","decodeAudioData","audioBuffer","combinedBuffer","AudioBuffer","combinedChannelData","getChannelData","slice","channelMerger","createChannelMerger","connect","destination","start","speak","loop","save"],"mappings":"AAAA,eAAe,MAAMA,KAAN,CAAY;AAE1BC,EAAAA,WAAW,GAAG;AACb,SAAKC,KAAL,GAAaC,MAAM,CAACC,eAApB;AACA,SAAKC,OAAL,GAAe,KAAKF,MAAM,CAACG,YAAP,IAAuBH,MAAM,CAACI,kBAAnC,GAAf;AACA,SAAKC,iBAAL,GAAyB,KAAKH,OAAL,CAAaI,4BAAb,EAAzB;AACA,SAAKC,OAAL,GAAe,KAAKL,OAAL,CAAaM,kBAAb,EAAf;AACA,SAAKC,OAAL,GAAe,KAAKP,OAAL,CAAaM,kBAAb,EAAf;AACA,SAAKE,OAAL,GAAe,KAAKR,OAAL,CAAaM,kBAAb,EAAf;AACA,SAAKG,OAAL,GAAe,KAAKT,OAAL,CAAaM,kBAAb,EAAf;AACA,SAAKI,YAAL,GAAoB,KAAKV,OAAL,CAAaM,kBAAb,EAApB;AACA;;AAEDK,EAAAA,GAAG,CAACC,MAAD,EAAS;AACX,QAAIC,SAAS,CAACC,YAAV,IAA0BD,SAAS,CAACC,YAAV,CAAuBC,YAArD,EAAmE;AAC/DC,MAAAA,OAAO,CAACC,GAAR,CAAY,yBAAZ;AACAJ,MAAAA,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAqC;AAAEG,QAAAA,KAAK,EAAE;AAAT,OAArC,EACGC,IADH,CACSC,MAAD,IAAY;AACjB,cAAMC,aAAa,GAAG,IAAIC,aAAJ,CAAkBF,MAAlB,CAAtB;AACA,cAAMG,SAAS,GAAG,IAAIC,wBAAJ,CAA6BZ,MAA7B,CAAlB;;AACAW,QAAAA,SAAS,CAACE,KAAV,GAAkB,MAAM;AACvBJ,UAAAA,aAAa,CAACK,IAAd;;AACAL,UAAAA,aAAa,CAACM,eAAd,GAAiCC,CAAD,IAAO;AACtCA,YAAAA,CAAC,CAACC,IAAF,CAAOC,WAAP,GAAqBX,IAArB,CAA2BY,MAAD,IAAY;AACrCf,cAAAA,OAAO,CAACC,GAAR,CAAYc,MAAZ;AACA,mBAAK/B,OAAL,CAAagC,eAAb,CAA6BD,MAA7B,EAAsCE,WAAD,IAAiB;AACrDjB,gBAAAA,OAAO,CAACC,GAAR,CAAYgB,WAAZ;AACA,sBAAMC,cAAc,GAAG,IAAIC,WAAJ,CAAgB,KAAhB,EAAuB,KAAvB,CAAvB;AACA,sBAAMC,mBAAmB,GAAGH,WAAW,CAACI,cAAZ,CAA2B,CAA3B,IAAgCJ,WAAW,CAACI,cAAZ,CAA2B,CAA3B,EAA8BC,KAA9B,CAAoC,KAApC,CAA5D;AACA,sBAAMC,aAAa,GAAG,KAAKvC,OAAL,CAAawC,mBAAb,CAAiC,CAAjC,CAAtB;AAEH,qBAAKnC,OAAL,CAAa0B,MAAb,GAAsBG,cAAtB;AACG,qBAAK3B,OAAL,CAAawB,MAAb,GAAsBG,cAAtB;AACA,qBAAK1B,OAAL,CAAauB,MAAb,GAAsBG,cAAtB;AACA,qBAAKzB,OAAL,CAAasB,MAAb,GAAsBG,cAAtB;AACA,qBAAK7B,OAAL,CAAaoC,OAAb,CAAqB,KAAKzC,OAAL,CAAa0C,WAAlC;AACA,qBAAKnC,OAAL,CAAakC,OAAb,CAAqB,KAAKzC,OAAL,CAAa0C,WAAlC;AACA,qBAAKlC,OAAL,CAAaiC,OAAb,CAAqB,KAAKzC,OAAL,CAAa0C,WAAlC;AACA,qBAAKjC,OAAL,CAAagC,OAAb,CAAqB,KAAKzC,OAAL,CAAa0C,WAAlC;AACA,qBAAKrC,OAAL,CAAasC,KAAb;AACA,qBAAKpC,OAAL,CAAaoC,KAAb;AACA,qBAAKnC,OAAL,CAAamC,KAAb;AACA,qBAAKlC,OAAL,CAAakC,KAAb;AACA,eAlBD;AAmBA,aArBD;AAsBA,WAvBD;AAwBA,SA1BD;;AA4BAtB,QAAAA,aAAa,CAACsB,KAAd;AACA,aAAK9C,KAAL,CAAW+C,KAAX,CAAiBrB,SAAjB;AACA,OAlCH;AAoCE;AACN;;AAEDsB,EAAAA,IAAI,GAAG;AACN,QAAI,CAAC/C,MAAL,EAAa;AACZ;AACA;;AACD;AACA;;AAEDgD,EAAAA,IAAI,GAAG;AACN,QAAI,CAAChD,MAAL,EAAa;AACZ;AACA;;AACD;AACA;;AAnEyB","sourcesContent":["export default class Voice {\n\n\tconstructor() {\n\t\tthis.synth = window.speechSynthesis\n\t\tthis.context = new (window.AudioContext || window.webkitAudioContext)()\n\t\tthis.streamDestination = this.context.createMediaStreamDestination()\n\t\tthis.source1 = this.context.createBufferSource()\n\t\tthis.source2 = this.context.createBufferSource()\n\t\tthis.source3 = this.context.createBufferSource()\n\t\tthis.source4 = this.context.createBufferSource()\n\t\tthis.bufferSource = this.context.createBufferSource()\n\t}\n\n\tsay(script) {\n\t\tif (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n   \t\t\tconsole.log('getUserMedia supported.');\n   \t\t\tnavigator.mediaDevices.getUserMedia ({ audio: true })\n      \t\t.then((stream) => {\n      \t\t\tconst mediaRecorder = new MediaRecorder(stream);\n      \t\t\tconst utterance = new SpeechSynthesisUtterance(script);\n      \t\t\tutterance.onend = () => {\n      \t\t\t\tmediaRecorder.stop()\n      \t\t\t\tmediaRecorder.ondataavailable = (e) => {\n\t      \t\t\t\te.data.arrayBuffer().then((buffer) => {\n\t      \t\t\t\t\tconsole.log(buffer)\n\t      \t\t\t\t\tthis.context.decodeAudioData(buffer, (audioBuffer) => {\n\t      \t\t\t\t\t\tconsole.log(audioBuffer)\n\t      \t\t\t\t\t\tconst combinedBuffer = new AudioBuffer(22050, 22050)\n\t      \t\t\t\t\t\tconst combinedChannelData = audioBuffer.getChannelData(0) + audioBuffer.getChannelData(0).slice(10000)\n\t      \t\t\t\t\t\tconst channelMerger = this.context.createChannelMerger(4)\n\n\t\t  \t\t\t\t\t\tthis.source1.buffer = combinedBuffer\n\t\t      \t\t\t\t\tthis.source2.buffer = combinedBuffer\n\t\t      \t\t\t\t\tthis.source3.buffer = combinedBuffer\n\t\t      \t\t\t\t\tthis.source4.buffer = combinedBuffer\n\t\t      \t\t\t\t\tthis.source1.connect(this.context.destination)\n\t      \t\t\t\t\t\tthis.source2.connect(this.context.destination)\n\t      \t\t\t\t\t\tthis.source3.connect(this.context.destination)\n\t      \t\t\t\t\t\tthis.source4.connect(this.context.destination)\n\t\t      \t\t\t\t\tthis.source1.start()\n\t\t      \t\t\t\t\tthis.source2.start()\n\t\t      \t\t\t\t\tthis.source3.start()\n\t\t      \t\t\t\t\tthis.source4.start()\n\t      \t\t\t\t\t})\n\t      \t\t\t\t})\n      \t\t\t\t}\n      \t\t\t}\n\n      \t\t\tmediaRecorder.start()\n      \t\t\tthis.synth.speak(utterance)\n      \t\t})\n\n      \t}\n\t}\n\n\tloop() {\n\t\tif (!window) {\n\t\t\treturn\n\t\t}\n\t\treturn\n\t}\n\n\tsave() {\n\t\tif (!window) {\n\t\t\treturn\n\t\t}\n\t\treturn\n\t}\n\n}\n"]},"metadata":{},"sourceType":"module"}