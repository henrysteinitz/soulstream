{"ast":null,"code":"export default class Voice {\n  constructor() {\n    this.synth = window.speechSynthesis;\n  }\n\n  say(script) {\n    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n      console.log('getUserMedia supported.');\n      navigator.mediaDevices.getUserMedia({\n        audio: true\n      }).then(stream => {\n        const mediaRecorder = new MediaRecorder(stream);\n        const utterance = new SpeechSynthesisUtterance(script);\n\n        mediaRecorder.ondataavailable = e => {\n          console.log(e.data.arrayBuffer());\n        };\n\n        mediaRecorder.start();\n\n        utterance.onend = () => {\n          mediaRecorder.stop();\n        };\n\n        this.synth.speak(utterance);\n      });\n    }\n  }\n\n  loop() {\n    if (!window) {\n      return;\n    }\n\n    return;\n  }\n\n  save() {\n    if (!window) {\n      return;\n    }\n\n    return;\n  }\n\n}","map":{"version":3,"sources":["/Users/henrysteinitz/Desktop/soulstream/lib/voice/voice.js"],"names":["Voice","constructor","synth","window","speechSynthesis","say","script","navigator","mediaDevices","getUserMedia","console","log","audio","then","stream","mediaRecorder","MediaRecorder","utterance","SpeechSynthesisUtterance","ondataavailable","e","data","arrayBuffer","start","onend","stop","speak","loop","save"],"mappings":"AAAA,eAAe,MAAMA,KAAN,CAAY;AAE1BC,EAAAA,WAAW,GAAG;AACb,SAAKC,KAAL,GAAaC,MAAM,CAACC,eAApB;AACA;;AAEDC,EAAAA,GAAG,CAACC,MAAD,EAAS;AACX,QAAIC,SAAS,CAACC,YAAV,IAA0BD,SAAS,CAACC,YAAV,CAAuBC,YAArD,EAAmE;AAC/DC,MAAAA,OAAO,CAACC,GAAR,CAAY,yBAAZ;AACAJ,MAAAA,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAqC;AAAEG,QAAAA,KAAK,EAAE;AAAT,OAArC,EACGC,IADH,CACSC,MAAD,IAAY;AACjB,cAAMC,aAAa,GAAG,IAAIC,aAAJ,CAAkBF,MAAlB,CAAtB;AACA,cAAMG,SAAS,GAAG,IAAIC,wBAAJ,CAA6BZ,MAA7B,CAAlB;;AACAS,QAAAA,aAAa,CAACI,eAAd,GAAiCC,CAAD,IAAO;AACtCV,UAAAA,OAAO,CAACC,GAAR,CAAYS,CAAC,CAACC,IAAF,CAAOC,WAAP,EAAZ;AACA,SAFD;;AAGAP,QAAAA,aAAa,CAACQ,KAAd;;AACAN,QAAAA,SAAS,CAACO,KAAV,GAAkB,MAAM;AACvBT,UAAAA,aAAa,CAACU,IAAd;AACA,SAFD;;AAGA,aAAKvB,KAAL,CAAWwB,KAAX,CAAiBT,SAAjB;AACA,OAZH;AAaE;AAGN;;AAEDU,EAAAA,IAAI,GAAG;AACN,QAAI,CAACxB,MAAL,EAAa;AACZ;AACA;;AACD;AACA;;AAEDyB,EAAAA,IAAI,GAAG;AACN,QAAI,CAACzB,MAAL,EAAa;AACZ;AACA;;AACD;AACA;;AAvCyB","sourcesContent":["export default class Voice {\n\n\tconstructor() {\n\t\tthis.synth = window.speechSynthesis\n\t}\n\n\tsay(script) {\n\t\tif (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n   \t\t\tconsole.log('getUserMedia supported.');\n   \t\t\tnavigator.mediaDevices.getUserMedia ({ audio: true })\n      \t\t.then((stream) => {\n      \t\t\tconst mediaRecorder = new MediaRecorder(stream);\n      \t\t\tconst utterance = new SpeechSynthesisUtterance(script);\n      \t\t\tmediaRecorder.ondataavailable = (e) => {\n      \t\t\t\tconsole.log(e.data.arrayBuffer())\n      \t\t\t}\n      \t\t\tmediaRecorder.start()\n      \t\t\tutterance.onend = () => {\n      \t\t\t\tmediaRecorder.stop()\n      \t\t\t}\n      \t\t\tthis.synth.speak(utterance)\n      \t\t})\n      \t}\n\t\t\n\n\t}\n\n\tloop() {\n\t\tif (!window) {\n\t\t\treturn\n\t\t}\n\t\treturn\n\t}\n\n\tsave() {\n\t\tif (!window) {\n\t\t\treturn\n\t\t}\n\t\treturn\n\t}\n\n}\n"]},"metadata":{},"sourceType":"module"}